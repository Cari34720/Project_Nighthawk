import pandas as pd
import pickle
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# â€” Pfade zu deinen Dateien â€”
# Dein Testing-Datensatz (oder vorhandener eigener Datensatz)
own_path = r"C:\01_Programme\Projekt_Nele\data\Testing.csv"
# Externer Datensatz, z. B. der Kaggle-Disease/Symptoms-Datensatz
external_path = r"C:\01_Programme\Projekt_Nele\data\training.csv"

print("ğŸ“‚ Lade eigenen Datensatz:", own_path)
df_own = pd.read_csv(own_path)
print("âœ… Eigener Datensatz geladen, Form:", df_own.shape)

print("ğŸ“‚ Lade externen Datensatz:", external_path)
df_ext = pd.read_csv(external_path)
print("âœ… Externer Datensatz geladen, Form:", df_ext.shape)

# â€” Spaltennamen harmonisieren (Kleinbuchstaben, Unterstriche) â€”
df_own.columns = [c.strip().lower().replace(" ", "_") for c in df_own.columns]
df_ext.columns = [c.strip().lower().replace(" ", "_") for c in df_ext.columns]

print("â„¹ï¸ Eigene Spaltenbeispiele:", df_own.columns[:10])
print("â„¹ï¸ Externe Spaltenbeispiele:", df_ext.columns[:10])

# â€” Zielspalte (Diagnose) â€” hier: prognosis (in deinem Testing.csv) â€”
target = "prognosis"
if target not in df_own.columns:
    raise ValueError(f"Zielspalte '{target}' nicht in dem eigenen Datensatz vorhanden.")
if target not in df_ext.columns:
    raise ValueError(f"Zielspalte '{target}' nicht in dem externen Datensatz vorhanden.")

# â€” Gemeinsam genutzte Merkmale (Symptome) bestimmen â€”
features_common = [c for c in df_own.columns if c != target and c in df_ext.columns]

print("ğŸ” Gemeinsame Features (Symptome):", len(features_common), "Spalten")
print(features_common[:20])

# Subsets mit gemeinsamen Merkmalen + Ziel
X_own = df_own[features_common]
y_own = df_own[target]

X_ext = df_ext[features_common]
y_ext = df_ext[target]

print("âœ… Subsets erstellt:", X_own.shape, X_ext.shape)

# â€” Datasets kombinieren â€”
X_comb = pd.concat([X_own, X_ext], ignore_index=True)
y_comb = pd.concat([y_own, y_ext], ignore_index=True)

print("ğŸ”— Kombinierter Datensatz:", X_comb.shape, y_comb.shape)
print("ğŸ“Š Diagnoseverteilungen (kombiniert):")
print(y_comb.value_counts().head(10))

# â€” Split in Trainings- und Testdaten â€”
X_train, X_test, y_train, y_test = train_test_split(
    X_comb, y_comb, test_size=0.2, random_state=42, stratify=y_comb
)

print("ğŸ”§ Train/Test Split:", X_train.shape, X_test.shape)

# â€” Modell trainieren â€”
model = RandomForestClassifier(n_estimators=200, random_state=42)
model.fit(X_train, y_train)

# â€” Auf Testdaten prÃ¼fen â†’
y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ Genauigkeit auf Testdaten: {acc:.4f}")
print(classification_report(y_test, y_pred))

# â€” Modell + Feature-Namen speichern â€”
model_data = {"model": model, "features": features_common}
model_dir = r"C:\01_Programme\Projekt_Nele\model"
os.makedirs(model_dir, exist_ok=True)
model_file = os.path.join(model_dir, "diagnose_model.pkl")
with open(model_file, "wb") as f:
    pickle.dump(model_data, f)

print("ğŸ’¾ Modell gespeichert unter:", model_file)
